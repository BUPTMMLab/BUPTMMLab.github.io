<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Region-Aware Exposure Consistency Network for Mixed Exposure Correction | BUPTMMLab</title><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.0/css/all.min.css><meta name=description content="An effective Region-aware Exposure Correction Network (RECNet) is introduced that can handle mixed exposure by adaptively learning and bridging different regional exposure representations and an exposure contrastive regularization strategy under the constraints of intra-regional exposure consistency and inter-regional exposure continuity is proposed."><link rel=stylesheet href=/css/main.min.df34b0153fa1319eab0404d6d67f5c8cf3f0416e02003d820402c72b72984952.css integrity="sha256-3zSwFT+hMZ6rBATW1n9cjPPwQW4CAD2CBALHK3KYSVI=" crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.min.f6abb61f6b9b2e784eba22dfb93cd399ce30ee01825791830a2737d6bfcd2be9.css integrity="sha256-9qu2H2ubLnhOuiLfuTzTmc4w7gGCV5GDCic31r/NK+k=" crossorigin=anonymous><link rel=stylesheet href=/css/fontawesome-free/fontawesome.min.6fc54ad7f858066d7a20163a3700a27bf0d0db05f352e455209505c9f1cf0691.css integrity="sha256-b8VK1/hYBm16IBY6NwCie/DQ2wXzUuRVIJUFyfHPBpE=" crossorigin=anonymous><button id=backToTop class="w-12 h-12 fixed bottom-6 right-6 z-50 p-3 rounded-full bg-blue-600 text-white shadow-md hover:bg-blue-700 transition" aria-label="Back to top">
<i class="fa-solid fa-arrow-up"></i></button></head><body><header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col"><div class="flex items-center justify-between"><div class="flex items-center space-x-4"><img src=/images/BUPT_logo.png alt=Logo class="h-14 max-w-[20rem] object-contain"><div class="relative rounded-full py-1.5 px-6 hover:bg-zinc-200 text-xl font-bold uppercase"><h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto text-4xl text-transparent bg-clip-text bg-gradient-to-r from-blue-500 to-purple-600" href=https://BUPTMMLab.github.io/>BUPTMMLab</a></h2></div></div><div class="flex items-center space-x-4"><a href=/ class="text-l px-4 py-2 bg-zinc-100 hover:bg-zinc-200 rounded-full font-semibold text-black transition-colors">Home
</a><a href=/publications/ class="text-l px-4 py-2 bg-zinc-100 hover:bg-zinc-200 rounded-full font-semibold text-black transition-colors">Publications
</a><a href=/tags/ class="text-l px-4 py-2 bg-zinc-100 hover:bg-zinc-200 rounded-full font-semibold text-black transition-colors">Tags
</a><a href=/members/ class="text-l px-4 py-2 bg-zinc-100 hover:bg-zinc-200 rounded-full font-semibold text-black transition-colors">Members
</a><a href=/about/ class="text-l px-4 py-2 bg-zinc-100 hover:bg-zinc-200 rounded-full font-semibold text-black transition-colors">About</a></div></div></div></header><main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div class="items-center justify-center"><article><header class="flex flex-col justify-center items-center mx-auto"><div class="flex flex-wrap justify-center gap-6 mb-2"><span class="inline-block text-white font-semibold px-4 py-1 rounded-lg text-2xl shadow-md select-none" style="background:linear-gradient(to right,#f472b6,#8b5cf6,#3b82f6);-webkit-background-clip:text;-webkit-text-fill-color:transparent">AAAI</span></div><h1 id=title class="text-4xl text-center font-bold leading-normal">Region-Aware Exposure Consistency Network for Mixed Exposure Correction</h1><div class="text-gray-700 text-base font-medium flex flex-wrap justify-center mt-4"><a href=https://github.com/kravrolens class="text-blue-600 hover:underline">Jin Liu</a>
<sup class="align-top text-xs ml-0.5 text-gray-600 tracking-tight">1</sup>,&nbsp;
<a href=https://teacher.bupt.edu.cn/fuhuiyuan class="text-blue-600 hover:underline">Huiyuan Fu</a>
<sup class="align-top text-xs ml-0.5 text-gray-600 tracking-tight">1</sup>,&nbsp;
<a href="https://scholar.google.com/citations?user=kCecGEQAAAAJ" class="text-blue-600 hover:underline">Chuanming Wang</a>
<sup class="align-top text-xs ml-0.5 text-gray-600 tracking-tight">1</sup>,&nbsp;
<a href="https://scholar.google.com/citations?user=A-vcjvUAAAAJ" class="text-blue-600 hover:underline">Huadong Ma</a>
<sup class="align-top text-xs ml-0.5 text-gray-600 tracking-tight">1</sup></div><div class="mt-2 text-gray-600 text-sm text-center"><div><sup>1</sup> Beijing University of Posts and Telecommunications</div></div><div id=writer class="flex flex-col space-y-2"><span class="text-gray-700 text-base font-medium before:mr-2 before:opacity-50 space-x-4"><time datetime=2024-02-28T10:00:00+00:00>February 28, 2024</time></span></div><div class="flex flex-wrap justify-center gap-2 mt-6"><div><a href=https://arxiv.org/pdf/2402.18217 class="inline-block flex items-center gap-2 bg-blue-100 text-blue-800 text-m font-semibold px-3 py-1 rounded-full hover:bg-blue-200 transition"><i class="ai ai-arxiv"></i>
<span>arXiv</span></a></div><div><a href=https://ojs.aaai.org/index.php/AAAI/article/view/28154 class="inline-block flex items-center gap-2 bg-blue-100 text-blue-800 text-m font-semibold px-3 py-1 rounded-full hover:bg-blue-200 transition"><i class="fas fa-file-pdf"></i>
<span>Paper</span></a></div><div><a href=https://github.com/kravrolens/RECNet class="flex items-center gap-2 bg-blue-100 text-blue-800 text-m font-semibold px-3 py-1 rounded-full hover:bg-blue-200 transition"><i class="fa-brands fa-github"></i>
<span>Code</span></a></div></div><br><div id=tldr-box class="bg-white border border-gray-300 rounded-xl shadow-md p-4 hover:shadow-xl transition"><p><strong>TL;DR:</strong> An effective Region-aware Exposure Correction Network (RECNet) is introduced that can handle mixed exposure by adaptively learning and bridging different regional exposure representations and an exposure contrastive regularization strategy under the constraints of intra-regional exposure consistency and inter-regional exposure continuity is proposed.</p></div><br></header><figure id=featureimage class="flex justify-center"><img class="rounded-lg max-h-[500px] object-contain" src=https://BUPTMMLab.github.io/images/pubs/liu_aaai2024_RECNet_hu_673fdef9690e679a.png alt width=750 height=422></figure><div id=content class="prose max-w-none lg:prose-lg mb-8"><h2 id=abstract>Abstract</h2><p>Exposure correction aims to enhance images suffering from improper exposure to achieve satisfactory visual effects. Despite recent progress, existing methods generally mitigate either overexposure or underexposure in input images, and they still struggle to handle images with mixed exposure, i.e., one image incorporates both overexposed and underexposed regions. The mixed exposure distribution is non-uniform and leads to varying representation, which makes it challenging to address in a unified process. In this paper, we introduce an effective Region-aware Exposure Correction Network (RECNet) that can handle mixed exposure by adaptively learning and bridging different regional exposure representations. Specifically, to address the challenge posed by mixed exposure disparities, we develop a region-aware de-exposure module that effectively translates regional features of mixed exposure scenarios into an exposure-invariant feature space. Simultaneously, as de-exposure operation inevitably reduces discriminative information, we introduce a mixed-scale restoration unit that integrates exposure-invariant features and unprocessed features to recover local information. To further achieve a uniform exposure distribution in the global image, we propose an exposure contrastive regularization strategy under the constraints of intra-regional exposure consistency and inter-regional exposure continuity. Extensive experiments are conducted on various datasets, and the experimental results demonstrate the superiority and generalization of our proposed method. The code is released at: <a href=https://github.com/kravrolens/RECNet>https://github.com/kravrolens/RECNet</a>.</p><h2 id=qualitative-results>Qualitative Results</h2><div class="flex justify-center w-full not-prose"><figure class="w-full p-2 bg-gray-50 rounded-md shadow-sm text-center"><div class="inline-block m-0 w-full"><img src=/images/pubs/liu_aaai2024_visualcomparison.png alt="Visual Comparison" class="w-full h-auto object-cover rounded-md"></div><figcaption class="mt-2 text-m text-gray-600">Visualization results on the LCDP dataset of mixed exposure correction. Our model reconstructs the details in the overexposed regions (building and curtain) as well as the underexposed regions (grass and basket).</figcaption></figure></div></div><div class="mt-12 mb-10 bg-white rounded-xl shadow-md" id=BibTeX><div class="flex items-center justify-between px-4 py-4 bg-white border-b border-gray-300"><span class="text-xl font-semibold text-black">BibTeX</span>
<button onclick=copyBibtex() class="text-sm bg-gray-200 hover:bg-gray-300 px-3 py-1 rounded flex items-center gap-2 text-black">
<i class="fa-solid fa-copy"></i>
<span>Copy</span></button></div><pre class="mt-3 px-4 py-2 bg-white text-black text-sm overflow-x-auto whitespace-pre-wrap break-words leading-snug">
<code id=bibtex-content style=white-space:pre class="block whitespace-pre-line break-words text-black">@inproceedings{liuRegionAwareExposure2024,
  title = {Region-Aware Exposure Consistency Network for Mixed Exposure Correction},
  author = {Liu, Jin and Fu, Huiyuan and Wang, Chuanming and Ma, Huadong},      
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},      
  year = {2024} 
}
</code>    
</pre></div><style>.toast{position:fixed;bottom:1.5rem;right:1.5rem;z-index:9999;background-color:#1f2937;color:#fff;padding:.75rem 1rem;border-radius:.5rem;box-shadow:0 4px 14px rgba(0,0,0,.25);opacity:0;transition:opacity .3s ease-in-out;pointer-events:none;font-size:.875rem}.toast.show{opacity:1}</style><script>function copyBibtex(){const e=document.getElementById("bibtex-content").innerText;navigator.clipboard.writeText(e).then(()=>{showToast("BibTeX copied to clipboard!")})}function showToast(e){const t=document.createElement("div");t.className="toast",t.textContent=e,document.body.appendChild(t),void t.offsetWidth,t.classList.add("show"),setTimeout(()=>{t.classList.remove("show"),setTimeout(()=>t.remove(),300)},3e3)}</script><ul id=taxonomy class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto"><li class="font-semibold my-4">Tags:</li><li><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300 uppercase" href=/tags/exposure-correction/>Exposure Correction</a></li><li><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300 uppercase" href=/tags/aaai/>Aaai</a></li></ul></article></div></main><footer class="bg-zinc-100 py-10 md:py-14"><script>const btn=document.getElementById("backToTop");window.addEventListener("scroll",()=>{btn.classList.toggle("hidden",window.scrollY<100)}),btn.addEventListener("click",()=>{window.scrollTo({top:0,behavior:"smooth"})})</script><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div class="flex flex-wrap space-y-6 mb-4"><div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10"><a class="flex items-center group" href=https://BUPTMMLab.github.io/><span class="text-4xl font-semibold uppercase">BUPTMMLab</span></a><p class=font-semibold>Research on Multimedia and Multimodal Learning.<br>Multimedia Lab, Beijing University of Posts and Telecommunications.</p></div><div class="self-center flex flex-col w-full md:w-2/5"><ul id=social-media class="flex items-center space-x-4"><li><a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href=https://github.com/BUPTMMLab target=_blank rel="noopener noreferrer"><i class="fa-brands fa-github fa-xl"></i></a></li></ul></div></div><div class=my-8><ul class="flex items-center space-x-4"><li><a class="decoration-auto hover:underline font-semibold" href=/>Home</a></li><li><a class="decoration-auto hover:underline font-semibold" href=/publications/>Publications</a></li><li><a class="decoration-auto hover:underline font-semibold" href=/tags/>Tags</a></li><li><a class="decoration-auto hover:underline font-semibold" href=/members/>Members</a></li><li><a class="decoration-auto hover:underline font-semibold" href=/about/>About</a></li></ul></div><div class="border-t pt-4"><p class=text-sm>Copyright © 2025. All rights reserved.</p></div></div><div class="text-center text-gray-500 text-sm mt-4 space-x-4"><span>本站总访问量 <span id=busuanzi_value_site_pv>0</span> 次</span>
<span>访客人数 <span id=busuanzi_value_site_uv>0</span> 人</span></div><script src=/js/busuanzi.pure.mini.min.1c1e7fbaa98df67c212645a84aa3b7cbb1e5aeca16c576b935d9b8b89b6d7c55.js integrity="sha256-HB5/uqmN9nwhJkWoSqO3y7HlrsoWxXa5Ndm4uJttfFU=" defer></script></footer><script defer src=/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js integrity="sha256-R0+bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){var e=document.createElement("div");e.className="adsbox",e.style.height="1px",e.style.position="absolute",e.style.top="-1000px",document.body.appendChild(e),window.setTimeout(function(){var t,n=e.offsetHeight===0;document.body.removeChild(e),n&&(t=document.createElement("div"),t.id="ublock-warning",t.style.position="fixed",t.style.top="0",t.style.left="0",t.style.width="100%",t.style.padding="12px",t.style.backgroundColor="#ffcc00",t.style.color="#000",t.style.fontSize="16px",t.style.textAlign="center",t.style.zIndex="9999",t.style.opacity="0",t.style.transition="opacity 1s ease",t.innerHTML="Detect the AD blocker. For a better browsing experience, please consider disabling uBlock Origin or other ad blockers on this site. Thank you!",document.body.appendChild(t),setTimeout(function(){t.style.opacity="1"},100),setTimeout(function(){t.style.opacity="0",setTimeout(function(){t.remove()},1e3)},5e3))},100)})</script></body></html>