<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>BUPTMMLab</title><link>https://BUPTMMLab.github.io/</link><description>Recent content on BUPTMMLab</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 07 Jun 2025 17:31:29 +0800</lastBuildDate><atom:link href="https://BUPTMMLab.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>About BUPT MMLab</title><link>https://BUPTMMLab.github.io/about/</link><pubDate>Sat, 07 Jun 2025 17:31:29 +0800</pubDate><guid>https://BUPTMMLab.github.io/about/</guid><description>&lt;p>Work in progress&amp;hellip;&lt;/p></description></item><item><title>Team Members in MMLab</title><link>https://BUPTMMLab.github.io/members/</link><pubDate>Thu, 05 Jun 2025 19:33:14 +0800</pubDate><guid>https://BUPTMMLab.github.io/members/</guid><description>&lt;p>Work in progress&amp;hellip;&lt;/p></description></item><item><title>Learning Exposure Correction in Dynamic Scenes</title><link>https://BUPTMMLab.github.io/publications/2024/learning-exposure-correction-in-dynamic-scenes/</link><pubDate>Mon, 28 Oct 2024 10:00:00 +0000</pubDate><guid>https://BUPTMMLab.github.io/publications/2024/learning-exposure-correction-in-dynamic-scenes/</guid><description>&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>Exposure correction aims to enhance visual data suffering from improper exposures, which can greatly improve satisfactory visual effects. However, previous methods mainly focus on the image modality, and the video counterpart is less explored in the literature. Directly applying prior image-based methods to videos results in temporal incoherence with low visual quality. Through thorough investigation, we find that the development of relevant communities is limited by the absence of a benchmark dataset. Therefore, in this paper, we construct the first real-world paired video dataset, including both underexposure and overexposure dynamic scenes. To achieve spatial alignment, we utilize two DSLR cameras and a beam splitter to simultaneously capture improper and normal exposure videos. Additionally, we propose an end-to-end video exposure correction network, in which a dual-stream module is designed to deal with both underexposure and overexposure factors, enhancing the illumination based on Retinex theory. The extensive experiments based on various metrics and user studies demonstrate the significance of our dataset and the effectiveness of our method. The code and dataset are available at &lt;a href="https://github.com/kravrolens/VECNet">https://github.com/kravrolens/VECNet&lt;/a>.&lt;/p></description></item><item><title>Region-Aware Exposure Consistency Network for Mixed Exposure Correction</title><link>https://BUPTMMLab.github.io/publications/2024/region-aware-exposure-consistency-network-for-mixed-exposure-correction/</link><pubDate>Wed, 28 Feb 2024 10:00:00 +0000</pubDate><guid>https://BUPTMMLab.github.io/publications/2024/region-aware-exposure-consistency-network-for-mixed-exposure-correction/</guid><description>&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>Exposure correction aims to enhance images suffering from improper exposure to achieve satisfactory visual effects. Despite recent progress, existing methods generally mitigate either overexposure or underexposure in input images, and they still struggle to handle images with mixed exposure, i.e., one image incorporates both overexposed and underexposed regions. The mixed exposure distribution is non-uniform and leads to varying representation, which makes it challenging to address in a unified process. In this paper, we introduce an effective Region-aware Exposure Correction Network (RECNet) that can handle mixed exposure by adaptively learning and bridging different regional exposure representations. Specifically, to address the challenge posed by mixed exposure disparities, we develop a region-aware de-exposure module that effectively translates regional features of mixed exposure scenarios into an exposure-invariant feature space. Simultaneously, as de-exposure operation inevitably reduces discriminative information, we introduce a mixed-scale restoration unit that integrates exposure-invariant features and unprocessed features to recover local information. To further achieve a uniform exposure distribution in the global image, we propose an exposure contrastive regularization strategy under the constraints of intra-regional exposure consistency and inter-regional exposure continuity. Extensive experiments are conducted on various datasets, and the experimental results demonstrate the superiority and generalization of our proposed method. The code is released at: &lt;a href="https://github.com/kravrolens/RECNet">https://github.com/kravrolens/RECNet&lt;/a>.&lt;/p></description></item></channel></rss>